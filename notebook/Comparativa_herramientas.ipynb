{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7703887f-228a-4349-aa31-7a321d5e8bdb",
   "metadata": {},
   "source": [
    "# Comparativa de uso de Pandas, Duckdb, Polars, PySpark\n",
    "\n",
    "Vamos a hacer uso de las diferentes herramientas para tener un punto común dónde poder revisar cómo hacer las operaciones más comunes y que sirva como guia.\n",
    "\n",
    "Nos basaremos en lo que Polars llama [Contextos](https://pola-rs.github.io/polars/user-guide/concepts/contexts/):\n",
    "\n",
    "1. Ingesta de datos\n",
    "1. Manejo básico de atributos \n",
    "1. Selección\n",
    "1. Filtrado\n",
    "1. Nuevas columnas\n",
    "1. Agrupación / Agregación\n",
    "1. Gestión de valores nulos\n",
    "1. Borrado de columnas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df4ede6-12c3-493b-bd0b-bc0e74e9f0c5",
   "metadata": {},
   "source": [
    "---\n",
    "## APIs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdd64113-cff8-4e27-9559-1ef1746caab2",
   "metadata": {},
   "source": [
    "- [pandas](https://pandas.pydata.org/docs/reference/index.html)\n",
    "- [polars API lazy](https://pola-rs.github.io/polars/user-guide/concepts/lazy-vs-eager/#when-to-use-which)\n",
    "- [polars API Streaming](https://pola-rs.github.io/polars/user-guide/concepts/lazy-vs-eager/#when-to-use-which)\n",
    "- [duckdb API](https://duckdb.org/docs/api/python/reference/)\n",
    "- [pyspark](https://spark.apache.org/docs/latest/api/python/reference/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a46f3b-76a0-4282-8144-17a30ef127e9",
   "metadata": {},
   "source": [
    "## Tipos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df31f1-a1f7-4b5c-b473-26dbdfe239a0",
   "metadata": {},
   "source": [
    "- [Tipo de datos de Pandas](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes)\n",
    "- [Tipo de datos de Polars](https://pola-rs.github.io/polars/user-guide/concepts/data-types/)\n",
    "- [Tipo de datos de DuckDB](https://duckdb.org/docs/sql/data_types/overview)\n",
    "- [Tipo de datos de PySpark](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/data_types.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288eeed-1a29-4028-bdfb-9499b2a5f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd2cd0-6bcf-4451-855a-cdd4cd8f9c3e",
   "metadata": {},
   "source": [
    "### PySpark conlleva la instalación previa de los siguientes elementos:\n",
    "\n",
    "```shell\n",
    "# Instalar java\n",
    "brew install java\n",
    "brew info java\n",
    "sudo ln -sfn /opt/homebrew/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk\n",
    "echo 'export PATH=\"/opt/homebrew/opt/openjdk/bin:$PATH\"' >> ~/.zshrc\n",
    "java --version\n",
    "\n",
    "# Instalar apache spark\n",
    "brew install apache-spark\n",
    "\n",
    "# Dentro de .zshrc poner:\n",
    "# Variables para correr pyspark en jupyter notebook\n",
    "# visto en https://www.bmc.com/blogs/jupyter-notebooks-apache-spark/\n",
    "export PYSPARK_DRIVER_PYTHON='jupyter'\n",
    "export PYSPARK_DRIVER_PYTHON_OPTS='lab'\n",
    "export PYSPARK_PYTHON='python3'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16cff4c-46c0-42b7-a973-230cd6761b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@sujathamudadla1213/sparkcontext-vssparksession-c7c991af95\n",
    "# https://www.guru99.com/pyspark-tutorial.html\n",
    "# https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html\n",
    "from pyspark.sql import SparkSession\n",
    "#import pyspark.sql.functions as func\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSessionExample\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce66d9-5156-47c5-adcf-860577757ad7",
   "metadata": {},
   "source": [
    "---\n",
    "## Ingesta de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1cd554-4e60-41a1-9695-32ff0071d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = '../data/yellos_tripdata_2022.parquet'\n",
    "csv_file = '../data/yellow_tripdata_2022.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3488424f-10bf-4475-9346-7a406a32861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfpl.sample(n=1000, seed=42).write_parquet('../data/mini_yellows.parquet')\n",
    "parquet_file = '../data/mini_yellows.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76292db-1f54-4a9d-8bcb-a528d36245a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "dfpd= pd.read_parquet(parquet_file)\n",
    "dfpd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a52c1-495b-4f6f-a846-ce7324dadcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars\n",
    "dfpl = pl.read_parquet(parquet_file)\n",
    "dfpl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcef91c-e390-456b-be2d-d3279320e097",
   "metadata": {},
   "source": [
    "**duckdb**\n",
    "\n",
    "Existen varias formas para cargar cargar ficheros en memoria, asignándolos a una variable o creando una BD en memoria:\n",
    "\n",
    "```python\n",
    "db = duckdb.read_parquet(parquet_file)\n",
    "db.shape\n",
    "```\n",
    "\n",
    "*En este notebook cargaremos la tabla en memoria. [DB API](https://duckdb.org/docs/api/python/dbapi)*\n",
    "\n",
    "**Referencias interesantes:**\n",
    "\n",
    "[Cuál es la diferencia entre duckdb.sql y duckdb.execute](https://stackoverflow.com/a/77067172)\n",
    "\n",
    "[Diferentes opciones de ingesta](https://duckdb.org/docs/api/python/data_ingestion)\n",
    "\n",
    "[Referencia SQL](https://duckdb.org/docs/sql/introduction)\n",
    "\n",
    "[Eficiente SQL con Pandas sobre Duckdb](https://duckdb.org/2021/05/14/sql-on-pandas.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cdf7fd-3d27-4cd0-a246-4a15f2e30ff1",
   "metadata": {},
   "source": [
    "*ToDo*\n",
    "\n",
    "Revisar: \n",
    "- https://www.analyticsvidhya.com/blog/2021/12/the-guide-to-data-analysis-with-duckdb/\n",
    "- https://learnsql.com/blog/sql-basics-cheat-sheet/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833b8fc-3d36-41b8-ac30-471af23caab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb\n",
    "con = duckdb.connect(database=':memory:')\n",
    "# Creamos una variable con el nombre de la BD.\n",
    "table_name = 'db'\n",
    "\n",
    "sql = f'''\n",
    "create table {table_name} as select * from '{parquet_file}';\n",
    "'''\n",
    "con.sql(sql)\n",
    "\n",
    "shape = f'''\n",
    "-- En DuckDB, combinar la consulta para obtener filas y columnas en una tabla\n",
    "SELECT\n",
    "    (SELECT COUNT(*) FROM {table_name}) AS num_filas,\n",
    "    (SELECT COUNT(*) FROM information_schema.columns WHERE table_name = '{table_name}') AS num_columnas;\n",
    "'''\n",
    "print(con.sql(shape))\n",
    "print(f\"Tipo de dato usando `.sql` {type(con.sql(shape))}\")\n",
    "print(f\"Tipo de dato usando `.execute` {type(con.execute(shape))}\")\n",
    "# También se puede hacer directamente\n",
    "print(f\"\\nDe forma directa:\", con.sql(f'from {table_name};').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a06a4ca-6181-4c86-ba0b-04769f516c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spk = spark.read.parquet(parquet_file)\n",
    "print(f\"{spk.count()}, {len(spk.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec33801-a0a5-4705-8e50-f344f227a838",
   "metadata": {},
   "source": [
    "Nota:\n",
    "> `Duckdb` tiene funciones para poder convertir la tablas leidas en memoria a dataframes, tanto de `Polars` como de `Pandas`:\n",
    "```python\n",
    "# Dataframe de Polars\n",
    "dfpl = duckdb.read_parquet('../data/yellos_tripdata_2022.parquet').pl() \n",
    "# Dataframe de Pandas\n",
    "dfpd = duckdb.read_parquet('../data/yellos_tripdata_2022.parquet').df()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d8b40b-5dba-4e81-bc1c-c7915cc31175",
   "metadata": {},
   "source": [
    "---\n",
    "## Manejo básico de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac1298-73c0-4615-ba76-db32a85c91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "dfpd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc40905-07bd-49cd-ac15-f5362e889512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars\n",
    "dfpl.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417698f7-5866-422d-8bff-4c83a83de884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb\n",
    "# Estadísticas descriptivas para una tabla en DuckDB, en caso de tener los valores en una variable\n",
    "# db.describe()\n",
    "# En este caso la salida del describe de la BD es otro.\n",
    "print(con.sql('describe db;'))\n",
    "\n",
    "# Para conseguir la salida de describe de los dataframes con un reporte matemático de valores podemos utizar:\n",
    "sql = f'''\n",
    "FROM {table_name}\n",
    "'''\n",
    "con.sql(sql).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6e754-e815-4528-bb53-cd7cc036a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark\n",
    "spk.describe().show(truncate=False)\n",
    "spk.summary().show(truncate=False)\n",
    "# La salida está truncada y no hay forma de cambiarlo. Si queremos verlo mejor, simplemente lo convertimos a un DataFrame de Pandas. \n",
    "spk.summary().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92d172c-4180-4622-88a2-8f131e554918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "print(f\"{dfpd.info()}\\n\")\n",
    "print(f\"Columnas: \\n{dfpd.columns}\\n\")\n",
    "print(f\"Tipos de datos: \\n{dfpd.dtypes}\\n\")\n",
    "print(f\"Uso de memoria: \\n{dfpd.memory_usage()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af2224-09d7-4691-bc8f-66540d55a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars\n",
    "print(f\"Columnas: \\n{dfpl.columns}\\n\")\n",
    "print(f\"Tipos de datos: \\n{dfpl.dtypes}\\n\")\n",
    "print(f\"Tamaño estimado en memoria: \\n{dfpl.estimated_size('mb')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c2dad-4435-4754-80fd-4b557905e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb\n",
    "\n",
    "print(con.sql(f\"select * from information_schema.tables WHERE table_name = '{table_name}'\"))\n",
    "print(f\"Columnas: \\n{con.sql('from db').columns}\\n\")\n",
    "print(f\"Tipos de datos: \\n{con.sql('from db').dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71814553-dfae-4d8b-af40-3f3180be7908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark\n",
    "print(f\"{spk.printSchema()}\\n\")\n",
    "print(f\"Columnas: \\n{spk.columns}\\n\")\n",
    "print(f\"Tipos de datos: \\n{spk.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c520f835-2f16-4ff4-9b76-bd439f6533f4",
   "metadata": {},
   "source": [
    "---\n",
    "## Selección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d9ec7-2896-4c73-a806-4ccaff0e36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "# dfpd.loc[:,['VendorID', 'trip_distance']].head()\n",
    "dfpd[['VendorID', 'trip_distance']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae6d24-2e37-4061-b2b3-11d755d0de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars\n",
    "dfpl.select(\n",
    "    pl.col('VendorID'),\n",
    "    pl.col('trip_distance'),\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0dcfdf-98e3-431d-86ec-a90066b082d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb\n",
    "sql = '''\n",
    "SELECT VendorID, trip_distance\n",
    "FROM db\n",
    "LIMIT 5;\n",
    "'''\n",
    "con.sql(sql).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259f68a-f86b-45c5-9237-279f5ef953c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark\n",
    "spk.select('VendorID', 'trip_distance').limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f158a29-409d-4854-af76-1d39a5eec615",
   "metadata": {},
   "source": [
    "---\n",
    "## Filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad335951-bd8b-4e3f-85a8-d4afc51c2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "dfpd[dfpd.trip_distance > 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e9dce-8473-45bb-8c7f-8ff209a1d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars\n",
    "dfpl.filter(pl.col('trip_distance') > 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c758c7-1d6d-43de-863b-fc86357e617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb\n",
    "sql = '''\n",
    "from db\n",
    "where trip_distance > 25;\n",
    "'''\n",
    "con.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62621855-d5d2-4405-afef-abc349d92d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark\n",
    "spk.filter(spk.trip_distance > 25).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5cd69a-9531-412c-8607-e63ad853c6ac",
   "metadata": {},
   "source": [
    "---\n",
    "## Nuevas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec2de3-a4a1-49fe-b0d3-97546d8c60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "dfpd[['VendorID', 'trip_distance']][dfpd.trip_distance > 25].assign(new_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd7e4e-6f7a-4907-bf8b-e1a873edd5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars\n",
    "dfpl.select(pl.col('VendorID'),pl.col('trip_distance'),).filter(pl.col('trip_distance') > 25).with_columns(new_col= pl.lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeee262-e950-4b0f-a068-b308412876a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb\n",
    "sql = '''\n",
    "SELECT VendorID, trip_distance, 0 as new_col\n",
    "FROM db\n",
    "WHERE trip_distance > 25;\n",
    "'''\n",
    "con.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6dfe6f-65ff-42c0-8673-57e3d258158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si se quiere añadir una columna de forma fija utilizar el ALTER TABLE\n",
    "sql = f'''ALTER TABLE {table_name} ADD COLUMN new_col INTEGER DEFAULT 0;'''\n",
    "con.sql(sql)\n",
    "print(con.query(f'from {table_name} limit 5;'))\n",
    "# Dejamos la BD como estaba inicialmente\n",
    "con.query(f'ALTER TABLE {table_name} drop COLUMN new_col;')\n",
    "print(con.query(f'select * from {table_name} limit 5;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e6204-beeb-401c-b7ee-501b49900ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark\n",
    "from pyspark.sql.functions import lit\n",
    "spk.select('VendorID', 'trip_distance').filter(spk.trip_distance > 25).withColumn('new_col', lit(0)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268eba5-8283-44b9-9730-55a87196ad28",
   "metadata": {},
   "source": [
    "---\n",
    "## Agrupación / Agregación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243d383-4415-42c6-a6b6-6fb5137a8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "dfpd.groupby('VendorID').agg({'trip_distance': 'sum'}).sort_values('trip_distance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe62f7c-2ebd-4ca4-8540-a8d3707947c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars\n",
    "dfpl.group_by(\"VendorID\").agg(pl.col(\"trip_distance\").sum()).sort(\"trip_distance\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2569328-5807-49a2-a2fc-d38c9bbc68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb\n",
    "sql = f'''\n",
    "select VendorID, sum(trip_distance) as Distance\n",
    "from {table_name}\n",
    "group by VendorID\n",
    "order by Distance desc;\n",
    "'''\n",
    "con.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02760ba2-b40b-4996-9cf5-278869eb58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark\n",
    "from pyspark.sql.functions import sum, desc\n",
    "spk.groupBy('VendorID').agg(sum('trip_distance').alias('trip_distance')).sort(desc(\"trip_distance\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb015ea7-83cc-497b-a0f2-c45373821348",
   "metadata": {},
   "source": [
    "---\n",
    "## Borrado de columas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e32ce-aea1-49d2-b715-84d0edfbe76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos ayudamos para copiar los campos\n",
    "# dfpd.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f42f05-d0d5-424f-9268-1842990dd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "print(f\"Columnas totales: {len(dfpd.columns.tolist())}\")\n",
    "print(f\"Columnas totales despues del borrado: {len(dfpd.drop(['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count'], axis=1).columns.tolist())}\")\n",
    "# Este borrado no se hace efectivo ya que no machacamos el DataFrame original\n",
    "print(f\"Columnas totales: {len(dfpd.columns.tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a7928-27c0-4cc7-ba70-82efb2ff0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars\n",
    "print(f\"Columnas totales: {len(dfpl.columns)}\")\n",
    "print(f\"Columnas totales despues del borrado: {len(dfpl.drop(['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count']).columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42243f5b-a900-4f0b-a20f-25d17def655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb\n",
    "sql = f'''\n",
    "select * EXCLUDE (tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count)\n",
    "from {table_name};\n",
    "'''\n",
    "print(f\"Columnas totales: {len(con.sql(f'from {table_name};').columns)}\")\n",
    "print(f\"Columnas totales despues del borrado: {len(con.sql(sql).columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1e7a7-d4c7-42ce-a81e-7a4836ccdaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark\n",
    "print(f\"Columnas totales: {len(spk.columns)}\")\n",
    "print(f\"Columnas totales despues del borrado: {len(spk.drop('tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count').columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5037d2b5-c205-4e00-a1f8-5fa5de1e1279",
   "metadata": {},
   "source": [
    "---\n",
    "## Gestión de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c632619-b233-459c-9914-ecd79985bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "# https://pandas.pydata.org/docs/user_guide/missing_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d5481-202f-4a04-9503-92ab54abd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars\n",
    "# https://pola-rs.github.io/polars/user-guide/expressions/null/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd47f12-411c-4219-83df-17188fc001ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb\n",
    "# https://duckdb.org/docs/sql/data_types/nulls.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab819cd3-590a-4666-9f94-4fb155ee7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark\n",
    "# https://pub.towardsai.net/handle-missing-data-in-pyspark-3b5693fb04a4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd3c29-eb37-46e2-80af-90542e11887d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0eb97-e27e-4c72-8931-ba3b2fc9c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80597ed3-ba68-4014-b8c2-d4059bc15fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0cc77-66ee-441d-b730-eff2369b28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2ef8b-fecd-45e5-b8f3-73f7f45e06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad249aa3-fcd7-4484-8eb2-ec4e2341bbdc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a6870-974b-4ffc-b357-11c9afdd4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b571da-484f-4327-bd98-c1a4a6866f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa5884-b2f1-47b0-b6b1-de2c170a47b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d137426-b44d-4fda-bbbd-e209cf74b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f7291-35f4-4e89-8b70-bb4a8b8dd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad09e13-964b-4432-8597-aedf538407ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0f3a4-1c1c-4c3d-9cad-e1b9153e6b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1b10e-cfde-4491-9f62-4e9753a190b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba53109-6128-44a5-8f47-b4f5360b0e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
